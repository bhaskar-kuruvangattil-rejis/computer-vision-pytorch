{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Project - Getting Started\n",
    "\n",
    "This notebook provides a comprehensive introduction to our computer vision project using PyTorch. We'll cover:\n",
    "\n",
    "- Setting up the environment\n",
    "- Loading and exploring data\n",
    "- Building and training models\n",
    "- Evaluating results\n",
    "- Visualizing predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Custom modules\n",
    "from models.cnn_model import SimpleCNN, SimpleResNet\n",
    "from data.dataset import get_dataloaders, get_transforms\n",
    "from utils.training import Trainer, get_optimizer, get_scheduler\n",
    "from utils.visualization import (\n",
    "    show_batch, plot_confusion_matrix, visualize_predictions,\n",
    "    plot_class_distribution, visualize_feature_maps\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "Dataset: CIFAR10\n",
      "Model: SimpleCNN\n",
      "Batch size: 32\n",
      "Learning rate: 0.001\n",
      "Epochs: 50\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = \"../configs/config.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Dataset: {config['dataset']['name']}\")\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Batch size: {config['dataloader']['batch_size']}\")\n",
    "print(f\"Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"Epochs: {config['training']['epochs']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 18.8M/170M [00:33<04:28, 565kB/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loader, val_loader = \u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_dir\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataloader\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataloader\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_workers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cv_pytorch_project/notebooks/../src/data/dataset.py:122\u001b[39m, in \u001b[36mget_dataloaders\u001b[39m\u001b[34m(dataset_name, data_dir, batch_size, num_workers, input_size)\u001b[39m\n\u001b[32m    119\u001b[39m train_transform, val_transform = get_transforms(input_size, augment=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset_name.upper() == \u001b[33m'\u001b[39m\u001b[33mCIFAR10\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     train_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     val_dataset = datasets.CIFAR10(root=data_dir, train=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m    125\u001b[39m                                  download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=val_transform)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dataset_name.upper() == \u001b[33m'\u001b[39m\u001b[33mCIFAR100\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torchvision/datasets/cifar.py:66\u001b[39m, in \u001b[36mCIFAR10.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.train = train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torchvision/datasets/cifar.py:139\u001b[39m, in \u001b[36mCIFAR10.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torchvision/datasets/utils.py:391\u001b[39m, in \u001b[36mdownload_and_extract_archive\u001b[39m\u001b[34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[32m    389\u001b[39m     filename = os.path.basename(url)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m archive = os.path.join(download_root, filename)\n\u001b[32m    394\u001b[39m extract_archive(archive, extract_root, remove_finished)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torchvision/datasets/utils.py:130\u001b[39m, in \u001b[36mdownload_url\u001b[39m\u001b[34m(url, root, filename, md5, max_redirect_hops)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib.error.URLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[32m5\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torchvision/datasets/utils.py:30\u001b[39m, in \u001b[36m_urlretrieve\u001b[39m\u001b[34m(url, filename, chunk_size)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m urllib.request.urlopen(urllib.request.Request(url, headers={\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total=response.length, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk := \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     31\u001b[39m             fh.write(chunk)\n\u001b[32m     32\u001b[39m             pbar.update(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/http/client.py:466\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    465\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m s = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/ssl.py:1311\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1310\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/lib/python3.11/ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    dataset_name=config[\"dataset\"][\"name\"],\n",
    "    data_dir=config[\"dataset\"][\"data_dir\"],\n",
    "    batch_size=config[\"dataloader\"][\"batch_size\"],\n",
    "    num_workers=config[\"dataloader\"][\"num_workers\"],\n",
    "    input_size=tuple(config[\"dataset\"][\"input_size\"]),\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation samples: {len(val_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a batch of training images\n",
    "show_batch(\n",
    "    train_loader,\n",
    "    class_names=config[\"dataset\"][\"class_names\"],\n",
    "    num_images=8,\n",
    "    figsize=(15, 8),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Class Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all labels to analyze distribution\n",
    "all_labels = []\n",
    "for _, labels in train_loader:\n",
    "    all_labels.extend(labels.numpy())\n",
    "\n",
    "plot_class_distribution(\n",
    "    all_labels, class_names=config[\"dataset\"][\"class_names\"], figsize=(12, 6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and Initialize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "if config[\"model\"][\"name\"] == \"SimpleCNN\":\n",
    "    model = SimpleCNN(\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        input_channels=config[\"model\"][\"input_channels\"],\n",
    "    )\n",
    "elif config[\"model\"][\"name\"] == \"SimpleResNet\":\n",
    "    model = SimpleResNet(\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        input_channels=config[\"model\"][\"input_channels\"],\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model: {config['model']['name']}\")\n",
    "\n",
    "print(f\"Model created: {config['model']['name']}\")\n",
    "print(f\"Model parameters: {model.count_parameters():,}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Test model with a dummy input\n",
    "dummy_input = torch.randn(1, 3, *config[\"dataset\"][\"input_size\"]).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "    print(f\"\\nOutput shape: {output.shape}\")\n",
    "    print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up Training Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = get_optimizer(\n",
    "    model=model,\n",
    "    optimizer_name=config[\"training\"][\"optimizer\"],\n",
    "    lr=config[\"training\"][\"learning_rate\"],\n",
    "    **config[\"training\"][\"optimizer_params\"],\n",
    ")\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = get_scheduler(\n",
    "    optimizer=optimizer,\n",
    "    scheduler_name=config[\"training\"][\"scheduler\"][\"name\"],\n",
    "    **{k: v for k, v in config[\"training\"][\"scheduler\"].items() if k != \"name\"},\n",
    ")\n",
    "\n",
    "# Create loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Scheduler: {scheduler.__class__.__name__}\")\n",
    "print(f\"Loss function: {criterion.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Note: You might want to reduce epochs for quick testing\n",
    "num_epochs = 5  # Reduced for demonstration, change to config['training']['epochs'] for full training\n",
    "\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=num_epochs,\n",
    "    save_best=True,\n",
    "    save_path=f\"{config['logging']['model_save_dir']}/best_model.pth\",\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "trainer.plot_training_history(\n",
    "    save_path=f\"{config['logging']['figure_save_dir']}/training_history.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "results = trainer.evaluate(\n",
    "    test_loader=val_loader, class_names=config[\"dataset\"][\"class_names\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Validation Loss: {results['test_loss']:.4f}\")\n",
    "print(f\"Validation Accuracy: {results['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_true=results[\"targets\"],\n",
    "    y_pred=results[\"predictions\"],\n",
    "    class_names=config[\"dataset\"][\"class_names\"],\n",
    "    figsize=(10, 8),\n",
    "    save_path=f\"{config['logging']['figure_save_dir']}/confusion_matrix.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model predictions\n",
    "visualize_predictions(\n",
    "    model=model,\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    class_names=config[\"dataset\"][\"class_names\"],\n",
    "    num_images=config[\"visualization\"][\"num_prediction_samples\"],\n",
    "    figsize=(20, 12),\n",
    "    save_path=f\"{config['logging']['figure_save_dir']}/predictions.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Visualization (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample image for feature visualization\n",
    "data_iter = iter(val_loader)\n",
    "sample_images, sample_labels = next(data_iter)\n",
    "sample_image = sample_images[0]  # Take first image\n",
    "\n",
    "# Visualize feature maps from the first convolutional layer\n",
    "try:\n",
    "    visualize_feature_maps(\n",
    "        model=model,\n",
    "        image=sample_image,\n",
    "        layer_name=\"conv1\",  # This might need adjustment based on your model\n",
    "        device=device,\n",
    "        max_maps=16,\n",
    "        figsize=(15, 10),\n",
    "        save_path=f\"{config['logging']['figure_save_dir']}/feature_maps.png\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Feature visualization failed: {e}\")\n",
    "    print(\"You might need to adjust the layer_name parameter.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save and Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "final_model_path = f\"{config['logging']['model_save_dir']}/final_model.pth\"\n",
    "model.save_model(final_model_path)\n",
    "\n",
    "# Demonstrate loading the model\n",
    "# Create a new model instance\n",
    "if config[\"model\"][\"name\"] == \"SimpleCNN\":\n",
    "    loaded_model = SimpleCNN(\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        input_channels=config[\"model\"][\"input_channels\"],\n",
    "    )\n",
    "elif config[\"model\"][\"name\"] == \"SimpleResNet\":\n",
    "    loaded_model = SimpleResNet(\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        input_channels=config[\"model\"][\"input_channels\"],\n",
    "    )\n",
    "\n",
    "# Load the saved weights\n",
    "loaded_model.load_model(final_model_path, device=str(device))\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Model saved and loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Next Steps and Improvements\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "- Set up a computer vision project with PyTorch\n",
    "- Loaded and explored your dataset\n",
    "- Built and trained a neural network\n",
    "- Evaluated model performance\n",
    "- Visualized results\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "1. **Data Augmentation**: Experiment with different augmentation techniques\n",
    "2. **Model Architecture**: Try different architectures (ResNet, EfficientNet, Vision Transformers)\n",
    "3. **Hyperparameter Tuning**: Use techniques like grid search or Bayesian optimization\n",
    "4. **Transfer Learning**: Use pre-trained models and fine-tune them\n",
    "5. **Advanced Techniques**: Implement techniques like mixup, cutmix, or label smoothing\n",
    "6. **Model Interpretability**: Use techniques like Grad-CAM for better understanding\n",
    "7. **Deployment**: Convert models to ONNX or TensorRT for production deployment\n",
    "\n",
    "### Creating More Notebooks:\n",
    "\n",
    "- `02_advanced_models.ipynb`: Implement advanced architectures\n",
    "- `03_transfer_learning.ipynb`: Use pre-trained models\n",
    "- `04_hyperparameter_tuning.ipynb`: Optimize hyperparameters\n",
    "- `05_model_interpretability.ipynb`: Understand model decisions\n",
    "- `06_deployment.ipynb`: Deploy models for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provided a complete end-to-end workflow for computer vision projects. The modular structure makes it easy to experiment with different components while maintaining clean, organized code.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pyenv 3.11.6)",
   "language": "python",
   "name": "pyenv-3.11.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
